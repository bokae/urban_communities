{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import time\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Community Survey -- data queries\n",
    "original script can be found in the repository of 'Universal patterns of long-distance commuting and social assortativity in cities' as '_script09-C_census_data_top25.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data to query on the top 50 metro areas\n",
    "metrodata = pd.read_csv('../data/cbsa-est2018-alldata.csv', encoding = \"ISO-8859-1\")\n",
    "metrodata = metrodata.drop_duplicates(subset=[\"CBSA\"])\n",
    "metrodata = metrodata.loc[:,[\"CBSA\",\"NAME\",\"CENSUS2010POP\"]].drop_duplicates().sort_values(by=\"CENSUS2010POP\",ascending=False).reset_index(drop=True)\n",
    "metrodata = metrodata.reset_index().reset_index()[[\"level_0\",\"CBSA\",\"NAME\",\"CENSUS2010POP\"]]\n",
    "metrodata.rename({\"level_0\":\"rank\",\"CBSA\":\"cbsacode\",\"NAME\":\"name\",\"CENSUS2010POP\":\"population\"},axis=1,inplace=True)\n",
    "metrodata[\"short_name\"] = metrodata[\"name\"].map(lambda s: s.split(\"-\")[0].split(\",\")[0])\n",
    "\n",
    "# filter mterodata to top50\n",
    "top50 = metrodata[metrodata['population'] > metrodata.iloc[50]['population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fips\n",
    "metro_to_county = pd.read_csv('../data/cbsa2fipsxw.csv')\n",
    "metro_to_county = metro_to_county.loc[:,['cbsacode', 'fipsstatecode', 'fipscountycode']].dropna()\n",
    "\n",
    "metro_to_county['cbsacode'] = metro_to_county['cbsacode'].map(int)\n",
    "metro_to_county.set_index('cbsacode',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe with all the information for the queries\n",
    "to_query = pd.merge(top50, metro_to_county,how='left',left_on='cbsacode',right_index=True)[['rank','short_name','cbsacode','fipsstatecode','fipscountycode']].dropna()\n",
    "to_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS codes for data we are interested in\n",
    "code_list = {\n",
    "    \"B01003_001\":\"population\",\n",
    "    \"B15003_022\":\"education_bachelor\", \n",
    "    \"B15003_001\":\"education_total\", \n",
    "    \"B19301_001\":\"income\",\n",
    "    \"B02001_001\":\"race_total\",\n",
    "    \"B02001_002\":\"white\",\n",
    "    \"B02001_003\":\"black\",\n",
    "    \"B02001_004\":\"native\",\n",
    "    \"B02001_005\":\"asian\"\n",
    "}\n",
    "\n",
    "# retrieving the estimates and their errors\n",
    "mode_list = {\n",
    "    \"E\":\"\",\n",
    "    \"M\":\"_error\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(code,mode,state,county):\n",
    "    \"\"\"\n",
    "    ACS 5-year estimate API queries.\n",
    "    \n",
    "    See https://www.census.gov/content/dam/Census/data/developers/api-user-guide/api-guide.pdf for details.\n",
    "    \"\"\"\n",
    "    query = \\\n",
    "        'https://api.census.gov/data/2013/acs/acs5?key=247942759169865ffc196d2f9fce9e9c94fc738b&get='+\\\n",
    "        code+\\\n",
    "        mode+\\\n",
    "        '&&for=tract:*&in=state:'+\\\n",
    "        str(state).zfill(2)+\\\n",
    "        '+county:'+\\\n",
    "        str(county).zfill(3)\n",
    "        \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(query):\n",
    "    \"\"\"\n",
    "    For a given ACS code (variable) and mode (estimate/margin of error), using the query, \n",
    "    returns a nicely formatted dataframe with the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # this line returns a response object\n",
    "        raw_response = request.urlopen(\n",
    "            query\n",
    "        )\n",
    "        # reading the string content from the response object (as if it were an open file)\n",
    "        str_response = raw_response.read()\n",
    "        #print(str_response)\n",
    "    except:\n",
    "        # jump if there is an error, e.g. because the API blocks us\n",
    "        str_response = ''\n",
    "\n",
    "    if str_response!='':\n",
    "        # if we got a response, parse the string into a list of lists\n",
    "        parsed_response = json.loads(str_response)\n",
    "        # first line is the header, rest is the data, convert data to DataFrame\n",
    "        data = pd.DataFrame(parsed_response[1:])\n",
    "        # renaming variable name to human readable form\n",
    "        # parsed_response[0][0] = code_list[code]+mode_list[mode]\n",
    "        # passing column names to the data\n",
    "        data.columns =  parsed_response[0]\n",
    "        # indexing data by geography for join purposes\n",
    "        data.set_index(['state','county','tract'],inplace=True)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating queries for the selected top metro areas\n",
    "def create_query_list(state,county):\n",
    "    \"\"\"\n",
    "    Creates all the queries for a given county based on the codes and modes listed in code_list and mode_list.\n",
    "    \"\"\"\n",
    "    return [create_query(code,mode,state,county) for code,mode in product(code_list,mode_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually creating all the queries in the dataframe\n",
    "to_query['queries'] = to_query[['fipsstatecode','fipscountycode']].apply(\n",
    "    lambda r: create_query_list(int(r['fipsstatecode']),int(r['fipscountycode'])),axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_flag=True\n",
    "\n",
    "def save_query_results(f,qlist):\n",
    "    \"\"\"\n",
    "    Saving query results into file continuously.\n",
    "    \"\"\"\n",
    "    # use outside reference of header_flag within function\n",
    "    global header_flag\n",
    "    # open output file for writing in append mode\n",
    "    file = open(f,'a')\n",
    "    try:\n",
    "        # get parsed response for all queries in query list created earlier\n",
    "        temp = list(map(get_data,qlist))\n",
    "    except:\n",
    "        # if there is no response, print queries\n",
    "        print(\"\\n\".join(qlist))\n",
    "    try:\n",
    "        # combine query results into one dataframe, putting education, race etc. columns together\n",
    "        # rows are different census tracts\n",
    "        df = pd.concat(temp,axis=1)\n",
    "        # rename columns from codes to human readable form\n",
    "        df.columns = [code_list[c[:-1]]+mode_list[c[-1]] for c in df.columns]\n",
    "        # write combined dataframe to output file\n",
    "        # if this is the first output, write header\n",
    "        df.to_csv(file,index=True,header=header_flag)\n",
    "        # if this is not the first output, omit header\n",
    "        header_flag=False\n",
    "        # close file\n",
    "        file.close()\n",
    "        return df\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"\\n\".join(qlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13842.479 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# looping over the desired queries\n",
    "start_time = time.time()\n",
    "\n",
    "f = '../data/censusdata-top50-2013.csv'\n",
    "\n",
    "# clearing file\n",
    "open(f,'w').close()\n",
    "header_flag=True\n",
    "to_query['results'] = to_query['queries'].map(lambda qlist: save_query_results(f,qlist))\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join(to_query['queries'].map(lambda l: '\\n'.join(l))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read IN all censusdata\n",
    "base_census2012 = pd.read_csv(\"../data/censusdata_top50_2012.csv\")\n",
    "census2013 = pd.read_csv('../data/censusdata-top50-2013.csv')\n",
    "census2014 = pd.read_csv('../data/censusdata-top50-2014.csv')\n",
    "census2015 = pd.read_csv('../data/censusdata-top50-2015.csv')\n",
    "census2016 = pd.read_csv('../data/censusdata-top50-2016.csv')\n",
    "base_census2017 = pd.read_csv(\"../data/censusdata_top50_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine key cols for Gergo\n",
    "key_cols = ['state', 'county', 'tract', 'population', 'income', 'education_bachelor', 'education_total', 'race_total', 'white', 'black', 'native', 'asian']\n",
    "base_census2012 = base_census2012[key_cols]\n",
    "census2013 = census2013[key_cols]\n",
    "census2014 = census2014[key_cols]\n",
    "census2015 = census2015[key_cols]\n",
    "census2016 = census2016[key_cols]\n",
    "base_census2017 = base_census2017[key_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38788, 57)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge part\n",
    "census_combined = pd.merge(base_census2012, census2013, on=[\"state\", \"county\", \"tract\"], how=\"left\", suffixes=[\"2012\", \"2013\"])\n",
    "census_combined = pd.merge(census_combined, census2014, on=[\"state\", \"county\", \"tract\"], how=\"left\")\n",
    "census_combined = pd.merge(census_combined, census2015, on=[\"state\", \"county\", \"tract\"], how=\"left\", suffixes=[\"2014\", \"2015\"])\n",
    "census_combined = pd.merge(census_combined, census2016, on=[\"state\", \"county\", \"tract\"], how=\"left\")\n",
    "census_combined = pd.merge(census_combined, base_census2017, on=[\"state\", \"county\", \"tract\"], how=\"left\", suffixes=[\"2016\", \"2017\"])\n",
    "census_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add censustract ID\n",
    "def create_geoid(row):\n",
    "    state = str(int(row[\"state\"])).zfill(2)\n",
    "    county = str(int(row[\"county\"])).zfill(3)\n",
    "    tract = str(int(row[\"tract\"])).zfill(6)\n",
    "    return \"14000US\" +state+county+tract\n",
    "\n",
    "census_combined['tract_id'] = census_combined.apply(create_geoid, axis=1)\n",
    "\n",
    "# clean up\n",
    "cols = census_combined.columns.to_list()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "census_combined = census_combined[cols]\n",
    "census_combined = census_combined.drop(columns=[\"state\", \"county\", \"tract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop -666666666.0 values\n",
    "census_combined = census_combined.replace([-666666666], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "census_combined.to_csv(\"../data/censustract_acs_2012_2017.csv\", index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
